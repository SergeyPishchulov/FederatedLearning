{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements\n",
    "\n",
    "* В данном соревновании мы имеем дело с последовательностями, один из интуитивных способов работы с ними - использование рекуррентных сетей. Данный бейзлайн посвящен тому, чтобы показать, как можно строить хорошие решения без использования сложного и трудоемкого feature engineering-а (чтобы эффективно решать ту же задачу с высоким качеством с помощью бустингов нужно несколько тысяч признаков), благодаря рекуррентным сетям. В этом ноутбуке мы построим решение с использованием фреймфорка `torch`. Для комфортной работы Вам понадобится машина с `GPU` (хватит ресурсов `google colab` или `kaggle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# добавим корневую папку, в ней лежат все необходимые полезные функции для обработки данных\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = \"../../../Datasets/AlfaBattle2.0/data_for_competition/\"\n",
    "# TRAIN_TRANSACTIONS_PATH = dir_path+'train_transactions_contest/'\n",
    "# TEST_TRANSACTIONS_PATH = dir_path+'test_transactions_contest/'\n",
    "\n",
    "# TRAIN_TARGET_PATH = dir_path+'train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '../../../train_transactions_contest/'\n",
    "TEST_TRANSACTIONS_PATH = '../../../test_transactions_contest/'\n",
    "\n",
    "TRAIN_TARGET_PATH = '../../../train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_frame = pd.read_csv(TRAIN_TARGET_PATH)\n",
    "# target_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как и в случае с бустингами, мы не можем поместить всю выборку в память, в виду, например, ограниченных ресурсов. Для итеративного чтения данных нам потребуется функция `utils.read_parquet_dataset_from_local`, которая читает N частей датасета за раз в память.\n",
    "\n",
    "\n",
    "* Нейронные сети требуют отделнього внимания к тому, как будут поданы и обработаны данные. Важные моменты, на которые требуется обратить внимание:\n",
    "    * Использование рекуррентных сетей подразумевает работу на уровне последовательностей, где одна последовательность - все исторические транзакции клиента. Чтобы преобразовать `pd.DataFrame` с транзакциями клиентов в табличном виде к последовательностям, мы подготовили функцию `dataset_preprocessing_utils.transform_transactions_to_sequences`, она делает необходимые манипуляции и возвращает фрейм с двумя колонками: `app_id` и `sequences`. Колонка `sequence` представляет из себя массив массивов длины `len(features)`, где каждый вложенный массив - значения одного конкретного признака во всех транзакциях клиента. \n",
    "    \n",
    "    * каждый клиент имеет различную по длине историю транзакций. При этом обучение сетей происходит батчами, что требует делать паддинги в последовательностях. Довольно неэффективно делать паддинг внутри батча на последовательностях случайной длины (довольно часто будем делать большой и бесполезный паддинг). Гораздо лучше использовать технику `sequence_bucketing` (о ней рассказано в образовательном ролике к данному бейзлайну). Для этого мы предоставляем функцию `dataset_preprocessing_utils.create_padded_buckets`. Один из аргументов в данную функцию - `bucket_info` - словарь, где для конкретной длины последовательности указано до какой длины нужно делать паддинг. Мы предоставялем для старта простой вид разбиения на 100 бакетов и файл где лежит отображение каждой длины в падднг (файл `buckets_info.pkl`).\n",
    "    \n",
    "    * Такие признаки, как [`amnt`, `days_before`, `hour_diff`] по своей природе не являются категориальными. Вы в праве самостоятельно выбирать способ работы с ними (модифицируя функции бейзлайна или адаптируя под себя). В рамках бейзлайна мы предлагаем интерпретировать каждую не категориальную фичу как категориальную. Для этого нужно подготовить bin-ы для каждой фичи. Мы предлагаем простой способ разбиения по бинам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL UTILS FROM .PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразует их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset) \n",
    "                              if filename.startswith('part')])\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
    "            'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category', 'day_of_week',\n",
    "            'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "embedding_projection = {'currency': (11, 6),\n",
    "                        'operation_kind': (7, 5),\n",
    "                        'card_type': (175, 29),\n",
    "                        'operation_type': (22, 9),\n",
    "                        'operation_type_group': (4, 3),\n",
    "                        'ecommerce_flag': (3, 3),\n",
    "                        'payment_system': (7, 5),\n",
    "                        'income_flag': (3, 3),\n",
    "                        'mcc': (108, 22),\n",
    "                        'country': (24, 9),\n",
    "                        'city': (163, 28),\n",
    "                        'mcc_category': (28, 10),\n",
    "                        'day_of_week': (7, 5),\n",
    "                        'hour': (24, 9),\n",
    "                        'weekofyear': (53, 15),\n",
    "                        'amnt': (10, 6),\n",
    "                        'days_before': (23, 9),\n",
    "                        'hour_diff': (10, 6)}\n",
    "\n",
    "\n",
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    \"\"\"\n",
    "    принимает список списков (array) и делает padding каждого вложенного списка до max_len\n",
    "    :param array: список списков\n",
    "    :param max_len: максимальная длина до которой нужно сделать padding\n",
    "    :return: np.array после padding каждого вложенного списка до одинаковой длины\n",
    "    \"\"\"\n",
    "    add_zeros = max_len - len(array[0])\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    принимает frame с транзакциями клиентов, сортирует транзакции по клиентам\n",
    "    (внутри клиента сортирует транзакции по возрастанию), берет num_last_transactions танзакций,\n",
    "    возвращает новый pd.DataFrame с двумя колонками: app_id и sequences.\n",
    "    каждое значение в колонке sequences - это список списков.\n",
    "    каждый список - значение одного конкретного признака во всех клиентских транзакциях.\n",
    "    Всего признаков len(features), поэтому будет len(features) списков.\n",
    "    Данная функция крайне полезна для подготовки датасета для работы с нейронными сетями.\n",
    "    :param transactions_frame: фрейм с транзакциями клиентов\n",
    "    :param num_last_transactions: количество транзакций клиента, которые будут рассмотрены\n",
    "    :return: pd.DataFrame из двух колонок (app_id, sequences)\n",
    "    \"\"\"\n",
    "    return transactions_frame \\\n",
    "        .sort_values(['app_id', 'transaction_number']) \\\n",
    "        .groupby(['app_id'])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})\n",
    "\n",
    "\n",
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    \"\"\"\n",
    "    Функция реализует sequence_bucketing технику для обучения нейронных сетей.\n",
    "    Принимает на вход frame_of_sequences (результат работы функции transform_transactions_to_sequences),\n",
    "    словарь bucket_info, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, далее группирует транзакции по бакетам (на основе длины), делает padding транзакций и сохраняет результат\n",
    "    в pickle файл, если нужно\n",
    "    :param frame_of_sequences: pd.DataFrame c транзакциями (результат применения transform_transactions_to_sequences)\n",
    "    :param bucket_info: словарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding\n",
    "    :param save_to_file_path: опциональный путь до файла, куда нужно сохранить результат\n",
    "    :param has_target: флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то\n",
    "    будет записано в результат\n",
    "    :return: возвращает словарь с следюущими ключами (padded_sequences, targets, app_id, products)\n",
    "    \"\"\"\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    app_ids = []\n",
    "    products = []\n",
    "\n",
    "    for size, bucket in tqdm(frame_of_sequences.groupby('bucket_idx'), desc='Extracting buckets'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket.flag.values)\n",
    "\n",
    "        app_ids.append(bucket.app_id.values)\n",
    "        products.append(bucket['product'].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        'padded_sequences': np.array(padded_seq),\n",
    "        'targets': np.array(targets) if targets else [],\n",
    "        'app_id': np.array(app_ids),\n",
    "        'products': np.array(products),\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "transaction_features = ['currency', 'operation_kind', 'card_type', 'operation_type',\n",
    "                        'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "                        'income_flag', 'mcc', 'country', 'city', 'mcc_category',\n",
    "                        'day_of_week', 'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "\n",
    "def batches_generator(list_of_paths, batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='torch', is_train=True):\n",
    "    \"\"\"\n",
    "    функция для создания батчей на вход для нейронной сети для моделей на keras и pytorch.\n",
    "    так же может использоваться как функция на стадии инференса\n",
    "    :param list_of_paths: путь до директории с предобработанными последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает list_of_paths и так же\n",
    "    перемешивает последовательности внутри файла\n",
    "    :param is_infinite: флаг, если True,  то создает бесконечный генератор батчей\n",
    "    :param verbose: флаг, если True, то печатает текущий обрабатываемый файл\n",
    "    :param device: device на который положить данные, если работа на торче\n",
    "    :param output_format: допустимые варианты ['tf', 'torch']. Если 'torch', то возвращает словарь,\n",
    "    где ключи - батчи из признаков, таргетов и app_id. Если 'tf', то возвращает картеж: лист input-ов\n",
    "    для модели, и список таргетов.\n",
    "    :param is_train: флаг, Если True, то для кераса вернет (X, y), где X - input-ы в модель, а y - таргеты, \n",
    "    если False, то в y будут app_id; для torch вернет словарь с ключами на device.\n",
    "    :return: бачт из последовательностей и таргетов (или app_id)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f'reading {path}')\n",
    "\n",
    "            with open(path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            padded_sequences, targets, products = data['padded_sequences'], data['targets'], data[\n",
    "                'products']\n",
    "            app_ids = data['app_id']\n",
    "            indices = np.arange(len(products))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                targets = targets[indices]\n",
    "                products = products[indices]\n",
    "                app_ids = app_ids[indices]\n",
    "\n",
    "            for idx in range(len(products)):\n",
    "                bucket, product = padded_sequences[idx], products[idx]\n",
    "                app_id = app_ids[idx]\n",
    "                \n",
    "                if is_train:\n",
    "                    target = targets[idx]\n",
    "                \n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = target[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    batch_products = product[jdx: jdx + batch_size]\n",
    "                    batch_app_ids = app_id[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    if output_format == 'tf':\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in\n",
    "                                           range(len(transaction_features))]\n",
    "                        \n",
    "                        # append product as input to tf model\n",
    "                        batch_sequences.append(batch_products)\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                             yield batch_sequences, batch_app_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device)\n",
    "                                           for i in range(len(transaction_features))]\n",
    "                        if is_train:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       label=torch.LongTensor(batch_targets).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "                        else:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "        if not is_infinite:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import read_parquet_dataset_from_local\n",
    "# from dataset_preprocessing_utils import transform_transactions_to_sequences, create_padded_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../constants/buckets_info.pkl', 'rb') as f:\n",
    "    mapping_seq_len_to_padded_len = pickle.load(f)\n",
    "    \n",
    "with open('../constants/dense_features_buckets.pkl', 'rb') as f:\n",
    "    dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Функция `create_buckets_from_transactions` ниже реализует следующий набор действий:\n",
    "    * Читает `num_parts_to_preprocess_at_once` частей датасета в память\n",
    "    * Преобразует вещественные и численные признаки к категориальным (используя `np.digitize` и подготовленные бины)\n",
    "    * Формирует фрейм с транзакциями в виде последовательностей с помощью `transform_transactions_to_sequences`.\n",
    "    * Если указан `frame_with_ids`, то использует `app_id` из `frame_with_ids` - актуально, чтобы выделить валидационную выборку.\n",
    "    * Реализует технику `sequence_bucketing` и сохраняет словарь обработанных последовательностей в `.pkl` файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets_from_transactions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once), \n",
    "                                   desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(path_to_dataset, step, \n",
    "                                                             num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=True)\n",
    "        for dense_col in ['amnt', 'days_before', 'hour_diff']:\n",
    "            transactions_frame[dense_col] = np.digitize(transactions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            \n",
    "        seq = transform_transactions_to_sequences(transactions_frame)\n",
    "        seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on='app_id')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            \n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разобьем имеющиеся данные на `train` и `val` части. Воспользуемся самым простым способом - для валидации используем 10% случайных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((867429, 3), (96382, 3))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(target_frame, random_state=42, test_size=0.1)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save val buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r ../../../tiny_val_buckets\n",
    "# ! mkdir ../../../tiny_val_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_buckets_from_transactions(TRAIN_TRANSACTIONS_PATH, \n",
    "#                                 save_to_path='../../../tiny_val_buckets',\n",
    "#                                 frame_with_ids=val, num_parts_to_preprocess_at_once=1, num_parts_total=500, has_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r ../../../val_buckets\n",
    "# ! mkdir ../../../val_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_buckets_from_transactions(TRAIN_TRANSACTIONS_PATH, \n",
    "#                                 save_to_path='../../../val_buckets',\n",
    "#                                 frame_with_ids=val, num_parts_to_preprocess_at_once=1, num_parts_total=50, has_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../tiny_val_buckets/processed_chunk_000.pkl',\n",
       " '../../../tiny_val_buckets/processed_chunk_001.pkl',\n",
       " '../../../tiny_val_buckets/processed_chunk_002.pkl',\n",
       " '../../../tiny_val_buckets/processed_chunk_003.pkl',\n",
       " '../../../tiny_val_buckets/processed_chunk_004.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_to_dataset = '../../../val_buckets'\n",
    "path_to_dataset = '../../../tiny_val_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save train buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r ../../../tiny_train_buckets\n",
    "# ! mkdir ../../../tiny_train_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_TRANSACTIONS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_buckets_from_transactions(TRAIN_TRANSACTIONS_PATH, \n",
    "#                                 save_to_path='../../../tiny_train_buckets',\n",
    "#                                 frame_with_ids=train, num_parts_to_preprocess_at_once=1, num_parts_total=500, has_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r ../../../train_buckets\n",
    "# ! mkdir ../../../train_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_buckets_from_transactions(TRAIN_TRANSACTIONS_PATH, \n",
    "#                                 save_to_path='../../../train_buckets',\n",
    "#                                 frame_with_ids=train, num_parts_to_preprocess_at_once=1, num_parts_total=50, has_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = '../../../train_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "# dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для создания модели будем использовать фреймворк `torch`. В нем есть все, чтобы писать произвольные сложные архитектуры и быстро эксперементировать. Для того, чтобы мониторить и логировать весь процесс во время обучения сетей, рекомендуется использовать надстройки над данным фреймворков, например, `lightning`.\n",
    "\n",
    "* В бейзлайне мы предлагаем базовые компоненты, чтобы можно было обучать нейронную сеть и отслеживать ее качество. Для этого вам предоставлены следующие функции:\n",
    "    * `data_generators.batches_generator` - функция-генератор, итеративно возвращает батчи, поддерживает батчи для `tensorflow.keras` и `torch.nn.module` моделей. В зависимости от флага `is_train` может быть использована для генерации батчей на train/val/test стадию.\n",
    "    * функция `pytorch_training.train_epoch` - обучает модель одну эпоху.\n",
    "    * функция `pytorch_training.eval_model` - проверяет качество модели на отложенной выборке и возвращает roc_auc_score.\n",
    "    * функция `pytorch_training.inference` - делает предикты на новых данных и готовит фрейм для проверяющей системы.\n",
    "    * класс `training_aux.EarlyStopping` - реализует early_stopping, сохраняя лучшую модель. Пример использования приведен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_generators import batches_generator, transaction_features\n",
    "# from pytorch_training import train_epoch, eval_model, inference\n",
    "# from training_aux import EarlyStopping#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все признаки в нашей модели будут категориальными. Для их представления в модели используем категориальные эмбеддинги. Для этого нужно каждому категориальному признаку задать размерность латентного пространства. Используем [формулу](https://forums.fast.ai/t/size-of-embedding-for-categorical-variables/42608) из библиотеки `fast.ai`. Все отображения хранятся в файле `embedding_projections.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../constants/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)\n",
    "# embedding_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Реализуем модель. Все входные признаки представим в виде эмбеддингов, сконкатенируем, чтобы получить векторное представление транзакции. Подадим последовательности в `GRU` рекуррентную сеть. Используем последнее скрытое состояние в качестве выхода сети. Представим признак `product` в виде отдельного эмбеддинга. Сконкатенируем его с выходом сети. На основе такого входа построим небольшой `MLP`, выступающий классификатором для целевой задачи. Используем градиентный спуск, чтобы решить оптимизационную задачу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionsRnn(nn.Module):\n",
    "    def __init__(self, transactions_cat_features, embedding_projections, product_col_name='product', rnn_units=128, top_classifier_units=32):\n",
    "        super(TransactionsRnn, self).__init__()\n",
    "        self._transaction_cat_embeddings = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) \n",
    "                                                          for feature in transactions_cat_features])\n",
    "                \n",
    "        self._product_embedding = self._create_embedding_projection(*embedding_projections[product_col_name], padding_idx=None)\n",
    "        \n",
    "        self._gru = nn.GRU(input_size=sum([embedding_projections[x][1] for x in transactions_cat_features]),\n",
    "                             hidden_size=rnn_units, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self._hidden_size = rnn_units\n",
    "                \n",
    "        self._top_classifier = nn.Linear(in_features=rnn_units+embedding_projections[product_col_name][1], \n",
    "                                         out_features=top_classifier_units)\n",
    "        self._intermediate_activation = nn.ReLU()\n",
    "        \n",
    "        self._head = nn.Linear(in_features=top_classifier_units, out_features=1)\n",
    "    \n",
    "    def forward(self, transactions_cat_features, product_feature):\n",
    "        batch_size = product_feature.shape[0]\n",
    "        \n",
    "        embeddings = [embedding(transactions_cat_features[i]) for i, embedding in enumerate(self._transaction_cat_embeddings)]\n",
    "        concated_embeddings = torch.cat(embeddings, dim=-1)\n",
    "        \n",
    "        _, last_hidden = self._gru(concated_embeddings)\n",
    "        last_hidden = torch.reshape(last_hidden.permute(1, 2, 0), shape=(batch_size, self._hidden_size))\n",
    "        \n",
    "        product_embed = self._product_embedding(product_feature)\n",
    "        \n",
    "        intermediate_concat = torch.cat([last_hidden, product_embed], dim=-1)\n",
    "                \n",
    "        classification_hidden = self._top_classifier(intermediate_concat)\n",
    "        activation = self._intermediate_activation(classification_hidden)\n",
    "        \n",
    "        logit = self._head(activation)\n",
    "        \n",
    "        return logit\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_embedding_projection(cls, cardinality, embed_size, add_missing=True, padding_idx=0):\n",
    "        add_missing = 1 if add_missing else 0\n",
    "        return nn.Embedding(num_embeddings=cardinality+add_missing, embedding_dim=embed_size, padding_idx=padding_idx)\n",
    "    \n",
    "def get_model():\n",
    "    return TransactionsRnn(transaction_features, embedding_projections,\n",
    "                                            rnn_units=4, top_classifier_units=4).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../../rnn_baseline/checkpoints/’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir ../../rnn_baseline/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../../rnn_baseline/checkpoints/pytorch_baseline\n",
    "! mkdir ../../rnn_baseline/checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для того, чтобы детектировать переобучение используем EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_checkpoints = '../../rnn_baseline/checkpoints/pytorch_baseline/'\n",
    "# es = EarlyStopping(patience=3, mode='max', verbose=True, \n",
    "#                    save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "#                    metric_name='ROC-AUC', save_format='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_CNT = 3\n",
    "# num_epochs =5#15\n",
    "# train_batch_size = 128\n",
    "# val_batch_szie = 128\n",
    "train_batch_size = val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model() #TransactionsRnn(transaction_features, embedding_projections, rnn_units=4, top_classifier_units=4 ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Запустим цикл обучения, каждую эпоху будем логировать лосс, а так же roc-auc на валидации и на обучении. Будем сохрнаять веса после каждой эпохи, а так же лучшие с помощью early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_constarint = 1\n",
    "dataset_val = dataset_val#[:file_num_constarint]\n",
    "dataset_train = dataset_train#[:file_num_constarint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [[x] for x in dataset_train]\n",
    "vals = [[x] for x in dataset_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zexi Li\n",
    "def fedavg(models, list_nums_local_data):\n",
    "    # feat_cnt= dict(models[0][0].named_parameters())['weight'].data.shape[1]\n",
    "    parameters = [m.state_dict() for m in models]\n",
    "    # parameters is a list of state_dicts\n",
    "    fedavg_global_params = copy.deepcopy(parameters[0])\n",
    "    for name_param in parameters[0]:\n",
    "        list_values_param = []\n",
    "        for dict_local_params, num_local_data in zip(parameters, list_nums_local_data):\n",
    "            list_values_param.append(dict_local_params[name_param] * num_local_data)\n",
    "        value_global_param = sum(list_values_param) / sum(list_nums_local_data)\n",
    "        fedavg_global_params[name_param] = value_global_param\n",
    "    # return fedavg_global_params\n",
    "    res = get_model()\n",
    "    res.load_state_dict(fedavg_global_params)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, dataset_train, dataset_val, model, dataset_name) -> None:\n",
    "        self.model = model\n",
    "        self.dataset_name = dataset_name\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())\n",
    "        self.dataset_train = dataset_train\n",
    "        self.dataset_val = dataset_val\n",
    "\n",
    "    def train_one_epoch(self, batch_size=64, shuffle=True,\n",
    "                        print_loss_every_n_batches=500, device=None, n_batches_to_train=None, verbose=False):\n",
    "        \"\"\"\n",
    "        делает одну эпоху обучения модели, логирует\n",
    "        :param model: nn.Module модель\n",
    "        :param optimizer: nn.optim оптимизатор\n",
    "        :param dataset_train: путь до директории с последовательностями\n",
    "        :param batch_size: размерм батча\n",
    "        :param shuffle: флаг, если True, то перемешивает данные\n",
    "        :param print_loss_every_n_batches: число батчей после которых логируется лосс на этих батчах\n",
    "        :param device: device, на который будут положены данные внутри батча\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        train_generator = batches_generator(self.dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                            device=device, is_train=True, output_format='torch')\n",
    "        # loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        num_batches = 1\n",
    "        running_loss = 0.0\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        for batch in tqdm(train_generator, \n",
    "                        #   desc=f'Training {self.dataset_train}'\n",
    "                          ):\n",
    "\n",
    "            output = torch.flatten(self.model(\n",
    "                batch['transactions_features'], batch['product']))\n",
    "\n",
    "            batch_loss = self.loss_function(output, batch['label'].float())\n",
    "\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            running_loss += batch_loss\n",
    "\n",
    "            if num_batches % print_loss_every_n_batches == 0:\n",
    "                print(\n",
    "                    f'Training loss after {num_batches} batches: {running_loss / num_batches}', end='\\r')\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "            if n_batches_to_train is not None and num_batches >= n_batches_to_train:\n",
    "                if verbose:\n",
    "                    print(f'Reached n_batches_to_train = {n_batches_to_train}')\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "            f'Training loss after epoch: {running_loss / num_batches}', end='\\r')\n",
    "\n",
    "    def eval_model(self, batch_size=32, device=None, custom_model=None,\n",
    "                   n_batches_to_val=None, verbose=False) -> float:\n",
    "        \"\"\"\n",
    "        функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
    "        выборке\n",
    "        :param model: nn.Module модель\n",
    "        :param dataset_val: путь до директории с последовательностями\n",
    "        :param batch_size: размер батча\n",
    "        :param device: device, на который будут положены данные внутри батча\n",
    "        :return: val roc-auc score\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        targets = []\n",
    "        val_generator = batches_generator(self.dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                          device=device, is_train=True, output_format='torch')\n",
    "        \n",
    "        model = custom_model if custom_model is not None else self.model\n",
    "\n",
    "        model.eval()\n",
    "        num_batches = 0\n",
    "        # for batch in tqdm(val_generator, desc='Evaluating model' if verbose else None):\n",
    "        for batch in val_generator:\n",
    "            targets.extend(batch['label'].detach().cpu().numpy().flatten())\n",
    "            output = model(batch['transactions_features'], batch['product'])\n",
    "            preds.extend(output.detach().cpu().numpy().flatten())\n",
    "            num_batches+=1\n",
    "        \n",
    "            if n_batches_to_val is not None and num_batches>n_batches_to_val:\n",
    "                if verbose:\n",
    "                    print(f'Reached n_batches_to_val = {n_batches_to_val}')\n",
    "                break\n",
    "\n",
    "        return roc_auc_score(targets, preds)\n",
    "\n",
    "\n",
    "trainers = []\n",
    "for i in range(CLIENTS_CNT):\n",
    "    trainers.append(Trainer(\n",
    "        dataset_train[5*i:5*(i+1)],\n",
    "                             dataset_val[:2],#TODO Note! Validation on the same set\n",
    "                            get_model(), f\"ds {i}\"\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plotly.colors.DEFAULT_PLOTLY_COLORS)\n",
    "color_by_dataset={}#\n",
    "for i,t in enumerate(trainers):\n",
    "    color_by_dataset[t.dataset_name] = colors[i]\n",
    "\n",
    "def get_line_mode(avg):\n",
    "    return {} if avg else {\"dash\": \"dot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c719c35d334fd88539c6f01b4210a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f812759c580347d79d8491c8563c7932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {}\n",
    "# VAL_ON = 25\n",
    "for m in ['local', 'avg']:\n",
    "    for ds in [t.dataset_name for t in trainers]:\n",
    "        metrics[(m, ds)] = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Test metrics during training. Epoch {epoch+1} completed.\")\n",
    "    for t in trainers:\n",
    "        t: Trainer\n",
    "        t.train_one_epoch(batch_size=train_batch_size,\n",
    "                          shuffle=True, print_loss_every_n_batches=10**10, device=device, \n",
    "                          n_batches_to_train=500)\n",
    "        val_metric = t.eval_model(\n",
    "            batch_size=val_batch_szie, device=device, n_batches_to_val=None)\n",
    "        metrics[('local', t.dataset_name)].append(val_metric)\n",
    "        s = pd.Series(metrics[('local', t.dataset_name)])\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=s.index,\n",
    "            y=s,\n",
    "            line=get_line_mode(False) | {\n",
    "                'color': color_by_dataset[t.dataset_name]},\n",
    "            name=f\"local {t.dataset_name}\"\n",
    "        ))\n",
    "\n",
    "    avg_model = fedavg([t.model for t in trainers],\n",
    "                       [1]*len(trainers))  # mock\n",
    "    for t in trainers:\n",
    "        val_metric = t.eval_model(\n",
    "            batch_size=val_batch_szie, device=device, custom_model=avg_model, n_batches_to_val=None)\n",
    "        metrics[('avg', t.dataset_name)].append(val_metric)\n",
    "        s = pd.Series(metrics[('avg', t.dataset_name)])\n",
    "        fig.add_trace(go.Scatter(x=s.index,\n",
    "                                 y=s,\n",
    "                                 line=get_line_mode(True) | {\n",
    "                                     'color': color_by_dataset[t.dataset_name]},\n",
    "                                 name=f\"avg on {t.dataset_name}\"))\n",
    "\n",
    "    # print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')\n",
    "\n",
    "    display(Image(fig.to_image(format=\"png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "rgb(31, 119, 180)",
          "dash": "dot"
         },
         "name": "local ds 0",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.4804761289846517,
          0.4865905401416765,
          0.4963003615702479,
          0.5265311393152301,
          0.6195128025383707,
          0.6221895292207793,
          0.6265569657615111,
          0.6377204471664699,
          0.6567222550177095,
          0.6623136806375443,
          0.6543941853600944,
          0.6685443108028335,
          0.6791460670011807,
          0.686563791322314,
          0.6811024203069659,
          0.6880921635182999,
          0.6913130903187721,
          0.6926791248524203,
          0.6954231847697756,
          0.6959397136953954
         ]
        },
        {
         "line": {
          "color": "rgb(255, 127, 14)",
          "dash": "dot"
         },
         "name": "local ds 1",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.5236321207201888,
          0.5114051431523022,
          0.6117270513577331,
          0.6200533131641086,
          0.6221793831168831,
          0.623193071133412,
          0.6250922373081464,
          0.6263392857142858,
          0.6270089285714285,
          0.6293056375442739,
          0.6333705357142858,
          0.642903261511216,
          0.6469312647579692,
          0.652176800472255,
          0.6452285640495868,
          0.6374031508264463,
          0.6365453438606847,
          0.6473574011216057,
          0.6571760625737899,
          0.6555185581463991
         ]
        },
        {
         "line": {
          "color": "rgb(44, 160, 44)",
          "dash": "dot"
         },
         "name": "local ds 2",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.3820856700118064,
          0.40019369834710744,
          0.3955144997048406,
          0.4478960670011806,
          0.5378108397284533,
          0.6503846295749705,
          0.6565331685360094,
          0.6556781286894923,
          0.6604827700708382,
          0.6629943919716647,
          0.6587394849468713,
          0.6475040584415584,
          0.6476894554309327,
          0.649858876918536,
          0.6392626549586777,
          0.6392202257969304,
          0.6367058367768594,
          0.6376743285123967,
          0.6424715909090909,
          0.6382572682998819
         ]
        },
        {
         "line": {
          "color": "rgb(31, 119, 180)"
         },
         "name": "avg ds 0",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.5800804309327037,
          0.5660529811097993,
          0.5690285566706021,
          0.5825643816410861,
          0.5885551948051948,
          0.5952958972845337,
          0.5969783057851239,
          0.5979301948051948,
          0.5975520218417946,
          0.6001180637544274,
          0.6036839580873672,
          0.6122029958677687,
          0.6128412780401415,
          0.6160824970484061,
          0.6123395070838253,
          0.6057316263282173,
          0.6077516233766235,
          0.6127933146399055,
          0.6125673332349469,
          0.6139582718417945
         ]
        },
        {
         "line": {
          "color": "rgb(255, 127, 14)"
         },
         "name": "avg ds 1",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.5800804309327037,
          0.5660529811097993,
          0.5690285566706021,
          0.5825643816410861,
          0.5885551948051948,
          0.5952958972845337,
          0.5969783057851239,
          0.5979301948051948,
          0.5975520218417946,
          0.6001180637544274,
          0.6036839580873672,
          0.6122029958677687,
          0.6128412780401415,
          0.6160824970484061,
          0.6123395070838253,
          0.6057316263282173,
          0.6077516233766235,
          0.6127933146399055,
          0.6125673332349469,
          0.6139582718417945
         ]
        },
        {
         "line": {
          "color": "rgb(44, 160, 44)"
         },
         "name": "avg ds 2",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.5800804309327037,
          0.5660529811097993,
          0.5690285566706021,
          0.5825643816410861,
          0.5885551948051948,
          0.5952958972845337,
          0.5969783057851239,
          0.5979301948051948,
          0.5975520218417946,
          0.6001180637544274,
          0.6036839580873672,
          0.6122029958677687,
          0.6128412780401415,
          0.6160824970484061,
          0.6123395070838253,
          0.6057316263282173,
          0.6077516233766235,
          0.6127933146399055,
          0.6125673332349469,
          0.6139582718417945
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Test metrics during training"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = list(plotly.colors.DEFAULT_PLOTLY_COLORS)\n",
    "color_by_dataset={}#\n",
    "for i,t in enumerate(trainers):\n",
    "    color_by_dataset[t.dataset_name] = colors[i]\n",
    "def get_line_mode(avg):\n",
    "    return {} if avg else {\"dash\": \"dot\"}\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(title_text=f\"Test metrics during training\")\n",
    "for i, ((stage, dataset), m) in enumerate(metrics.items()):\n",
    "    s = pd.Series(m)\n",
    "    d = \"dot\" if dataset=='local' else 'solid'\n",
    "    fig.add_trace(go.Scatter(x=s.index, y=s,line=get_line_mode(stage=='avg')|{'color':color_by_dataset[dataset]},name=f\"{stage} {dataset}\")\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6139582718417945\n",
      "0.6139582718417945\n",
      "0.6139582718417945\n"
     ]
    }
   ],
   "source": [
    "for t in trainers:\n",
    "        val_metric = t.eval_model(batch_size=val_batch_szie, device=device, custom_model=avg_model, n_batches_to_val=10**10)\n",
    "        print(val_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(0):\n",
    "#     print(f'Starting epoch {epoch+1}')\n",
    "#     train_epoch(model, optimizer, dataset_train, batch_size=train_batch_size, \n",
    "#                 shuffle=True, print_loss_every_n_batches=25, device=device, n_batches_to_train= 101)\n",
    "    \n",
    "#     val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie, device=device)\n",
    "#     es(val_roc_auc, model)\n",
    "    \n",
    "#     if es.early_stop:\n",
    "#         print('Early stopping reached. Stop training...')\n",
    "#         break\n",
    "#     torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt'))\n",
    "    \n",
    "#     train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie, device=device)\n",
    "#     print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все готово, чтобы сделать предсказания для тестовой выборки. Нужно только подготовить данные в том же формате, как и для train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../../../test_buckets\n",
    "! mkdir ../../../test_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1063622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1063624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id  product\n",
       "0  1063620        0\n",
       "1  1063621        0\n",
       "2  1063622        1\n",
       "3  1063623        1\n",
       "4  1063624        2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame = pd.read_csv('../../../test_target_contest.csv')\n",
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../train_transactions_contest/'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_TRANSACTIONS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../test_transactions_contest/'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_TRANSACTIONS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_buckets_from_transactions(TEST_TRANSACTIONS_PATH, \n",
    "#                                 save_to_path='../../../test_buckets', frame_with_ids=test_frame, \n",
    "#                                  num_parts_to_preprocess_at_once=10, num_parts_total=50, has_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_test_dataset = '../../../test_buckets/'\n",
    "dir_with_test_datasets = os.listdir(path_to_test_dataset)\n",
    "dataset_test = sorted([os.path.join(path_to_test_dataset, x) for x in dir_with_test_datasets])\n",
    "\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отдельный вопрос, какую из построенных моделей использовать для того, чтобы делать предсказания на тест. Можно выбирать лучшую по early_stopping. В таком случае есть риск, что мы подгонимся под валидационную выборку, особенно если она не является очень репрезентативной, однако это самый базовый вариант (используем его). Можно делать разные версии ансамблирования, используя веса с разных эпох. Такой подход требует дополнительного кода (обязательно попробуйте его!). Наконец, можно выбирать такую модель, которая показывает хорошие результаты на валидации и в то же время, не слишком переучена под train выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $path_to_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../rnn_baseline/checkpoints/pytorch_baseline/best_checkpoint.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/serhio/Data/1Education/FL/AlfaBattle2.0AuthorBaseline/AlfaBattle2.0AuthorBaseline/rnn_baseline/baseline/pytorch_baseline.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/serhio/Data/1Education/FL/AlfaBattle2.0AuthorBaseline/AlfaBattle2.0AuthorBaseline/rnn_baseline/baseline/pytorch_baseline.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path_to_checkpoints, \u001b[39m'\u001b[39;49m\u001b[39mbest_checkpoint.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../rnn_baseline/checkpoints/pytorch_baseline/best_checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, 'best_checkpoint.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21564d2f55394158a7cde265ffb9c016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Test time predictions'), FloatProgress(value=1.0, bar_style='info', layout=Layout(w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = inference(model, dataset_test, batch_size=128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063655</td>\n",
       "      <td>-3.865098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063672</td>\n",
       "      <td>-2.472911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1063694</td>\n",
       "      <td>-3.957081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063709</td>\n",
       "      <td>-3.381659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1063715</td>\n",
       "      <td>-4.051003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    app_id     score\n",
       "0  1063655 -3.865098\n",
       "1  1063672 -2.472911\n",
       "2  1063694 -3.957081\n",
       "3  1063709 -3.381659\n",
       "4  1063715 -4.051003"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds.to_csv('rnn_baseline_submission.csv', index=None) # ~ 0.750 на public test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
